# MusicGenerationWithGANs

Final Project for 6.867: Machine Learning

### Files

Each of the files and their uses are described below.

| File | Description |
| ------ | ------ |
| make_fma_dataset.py | Makes the dataset that we used that was composed of the FMA songs. |
| setup.sh | Setup scrit to run on AWS GPU to setup the server and install relvant libraries. |
| basic_wavenet.py | Model file for creating our implementation of wavenet. |
|train_basic_wavenet.py |  Training file for our implementation of wavenet. |
| model_with_experiments\train_with_dropout.py | Replace train.py with this to train with dropout. |
| model_with_experiments\model_with_leaky_relu.py | Replace model.py with this to train with leaky relu. |
| model_with_experiments\train_with_gradient_clipping.py | Replace train.py with this to train with gradient clipping.
| logging\ | All of the model checkpoints for our experiments.
| generated_music\ | 10 second samples generated from each of the models.


### Datasets

In addition to the FMA dataset (generated by make_fma_dataset.py), we used two datasets from youtube videos:
 -  [Classical Piano Music](https://www.youtube.com/watch?v=EhO_MrRfft)
  -  [Ambient Electronic Muisc](https://www.youtube.com/watch?v=Am1tG_adg6s)
